{"posts":[{"title":"Hadoop权威指南--4-关于YARN","content":"Apache YARN(Yet Another Resource Negotiator)是Hadoop的集群资源管理系统，提供请求和使用集群资源的API，这些API被更上层的分布式计算框架使用。 1、YARN的运行机制 YARN通过两类长期运行的守护进程提供自己的核心服务：负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台 资源管理器：主要是管理集群上资源的使用。 节点管理器：运行在集群所有的节点上，而且能够启动和监控容器。 容器：任务在申请到的资源后在节点上启动的进程 ApplicationMaster：一个特殊的进程，实际上是特定计算框架的一个实例。负责与资源管理器协商资源，并和节点管理器协同来执行和监控容器。 YARN的工作流程如下： 1、作业任务提交：用户将MapReduce或其它任务提交到集群。主要分以下几步： 客户端向集群提交作业 资源管理器向客户端返回分配新的作业ID和资源提交路径 客户端提交jar包，切片信息和配置文件到指定的资源提交路径 2、作业的初始化：当资源提交完成之后，就会开始作业的初始化步骤： 资源管理器会收到运行ApplicationMaster的请求，将该任务添加到容器调度器中 容器调度器会根据资源和队列的要求，选择一个合适的节点管理器 该节点管理器会创建一个特殊的容器，即ApplicationMaster 下载客户端提交的资源到本地 3、作业分配：如果作业只是运行一个简单的计算，就不要分配任务了。如果需要向资源管理器请求更多的容器，以运行一个分布式计算，就需要作业的分配。 ApplicationMaster向资源管理器请求容器来运行任务。会向这样的节点请求容器：存储该数据块三个复本的节点，或者是这些复本机架中的任何一个节点，如果都失败了，则申请集群中的任意节点。 容器申请成功后，资源管理器会通知对应的节点管理器领取任务，创建容器。 4、作业运行 资源管理器会给节点管理器发送容器启动脚本 ApplicationMaster等待作业运行完成，判断是否需要申请容器，运行reduce任务。 5、进度和状态更新 YARN中的任务将其进度和状态(包括容器)返回给ApplicationMaster, 客户端每秒向ApplicationMaster请求进度更新, 展示给用户。 6、作业完成 客户端会向ApplicationMaster请求作业是否完成，当作业完成时，相应的容器和ApplicationMaster会清理工作状态。 2、应用生命期 应用生命期有三种模型： 一个作业对应一个应用，MapReduce采用这个方式。 工作流的方式，效率更高，因为容器可以在作业之间重用。Spark采用这个方式。 多个用户共享一个长期运行的应用。这意味着用户将获得非常低延迟的查询响应。 YARN的最大优点在于向MapReduce以外的其它类型的分布式应用开放了Hadoop。 YARN中的调度 理想情况下，YARN应用发出的资源请求应该马上得到满足。然而资源是是有限，所以需要进行资源的调度。YARN调度器的工作就是根据既定策略为应用分配资源。 FIFO调度器：按照先进先出的顺序运行应用。简单易懂，不需要配置，但是不适合共享集群。 容量调度器：一个专门的队列保证小任务能够很快启动，但是牺牲了整个集群的使用率。 公平调度器：不需要预留资源，调度器会在所有运行的作业之间动态平衡资源。 ","link":"https://python-spider-wsc.github.io/post/hadoop-qwzn4-yarn/"},{"title":"Hadoop权威指南--第三章：Hadoop分布式文件系统","content":"Hadoop自带一个分布式文件系统，称为HDFS或者DFS 1、HDFS的设计 HDFS以流式数据访问模式来存储超大文件，运行于商用硬件集群上。 具有以下特点： 超大文件存储。对超大文件进行分区并存储到若干台独立的物理计算机上。 流式数据访问。HDFS的构建思路：一次写入，多次读取。流式数据访问只需要一次寻址，因此读取整个数据集的时间延迟更加重要。 商用硬件。HDFS能够容忍节点故障且不丢失任何数据，同时不会让用户察觉到明显的中断。 HDFS对以下应用并不合适，需要继续改进： 低时间延迟的数据访问。HDFS是为了高数据吞吐量应用优化的，这会以提高时间延迟为代价。目前对于低延迟访问，HBase是更好的选择。 大量的小文件。 namenode将文件系统的元数据（例如权限信息）存储到内存中，因此文件系统所能存储的文件总数受限于namenode的内存容量。 多用户写，任意修改文件。HDFS中的文件写入只支持单个写入者，而且总以”只添加“的方式在文件末尾写数据。也不支持在文件的任意位置进行修改。 2、HDFS的概念 2.1 数据块 HDFS上的文件也会被划分为块大小的多个分块 HDFS的块大小默认为128MB。块设置这么大，是为了最小化寻址开销。例如寻址时间为10ms，为了使寻址时间占传输时间的1%，那传输时间就是1s。而磁盘的传输速率为100MB/s，那块的大小应该是100MB。但是块大小也不会设置的太大，MapReduce中的map任务通常一次只处理一个块的数据。如果块太大，那块的数量就会太少，作业运行速度就会比较慢。 HDFS中小于一个块大小的文件也不会占据整个块的空间。 大于块大小的文件也不需要存储在同一个磁盘上，它们可以在集群上的任意磁盘上存储。 使用抽象块作为存储单元，而不是整个文件，可简化存储管理。计算单个磁盘可以存储多少个块就比较简单。 消除元数据的顾虑。块只要存储大块的数据就可以了，而文件的元数据可以由其它系统单独管理。 块非常是和用于数据的备份，进而提高数据的容错能力。 2.2 namenode 和datanode HDFS集群中有两类节点，即namenode 和 datanode。它们以管理节点-工作节点的模式运行（一个管理节点namenode和多个工作节点datanode）。 namenode管理文件系统的命名空间。 它维护着文件系统树及整棵树内的所有文件和目录，这些信息以两个文件的形式永久保存在本地磁盘上：命名空间镜像文件（fsimage）和编辑日志文件（edits）。在tmp/dfs/name/current目录下可以找到这些文件 同时也记录着每个文件中各个块所在的数据节点信息。这些信息不会永久保存。而是根据datanode重建。 为了防止edits中保存的最新变更记录过大，HDFS会定期合并fsimage和edits文件形成新的fsimage文件，然后重新记录edits文件。由于namenode只有一个，所以会把fsimage和edits的合并的工作放到SecondaryNameNode上（Hadoop2.0之后），以减少namenode的压力。 datanode是文件系统的工作节点。 根据需要存储或检索数据块 定期向namenode发送所存储块的列表 1、客户端连接到namenode，执行文件系统的“命名空间”操作，例如打开、关闭、重命名文件和目录，同时决定“数据块”到具体datanode节点的映射。 2、datanode在namenode的指挥下进行“数据块”的创建、删除和复制。 3、客户端连接到datanode，执行读写数据块操作。 对于访问频繁的文件，其对应的块可能会缓存在datanode的内存中。可以利用块缓存的优势提高读操作的性能。用户可以通过缓存池通知namenode需要缓存哪些文件以及缓存多久。 当文件储存时，每个块就会进行复制备份，一般是3份（可配置）。当datanode宕机时，会马上使用备份文件，同时根据最大备份数再次进行数据的备份。所以datanode宕机一般不会对数据造成影响。 但是如果namenode宕机，则整个文件系统将会无法使用。因此对namenode的容错非常重要。Hadoop一般提供两种机制： 对组成文件系统的元数据的持久文件进行备份，一般做法是：将持久状态写入本地磁盘的同时，写入一个远程挂载的网络文件系统（NFS） 运行一个辅助的namenode，即SecondaryNameNode。但是辅助的namenode保存的状态总是滞后于namenode，如果直接使用辅助namenode的元数据，难免会造成数据的丢失。一般是把存储在NFS的namenode元数据复制到辅助namenode并作为新的namenode运行。 namenode一般来说只有一个节点，那么该节点的内存大小将成为超大集群的限制瓶颈。Hadoop2.0之后的版本引入了联邦HDFS的概念，允许系统添加多个namenode来实现内存的扩展。在联邦环境下，每个namenode维护一个独立的命名空间卷，由命名空间的元数据和一个数据块池组成。两两之间不会相互影响和通信。集群中的datanode需要注册到每个namenode,而且存储着多个namenode中数据池中的数据块。 2.3 HDFS的高可用性 前面针对namenode的数据完整性的两大机制，但是namenode依然存在着单点失效的问题。如果namenode宕机了，那么所有的客户端均无法读写，因为namenode是唯一存储元数据和文件到数据块映射的地方。在这样的情况下，Hadoop系统直到新的namenode上线（按照两大机制上线）才能继续提供服务。这个过程需要系统管理员启动一个新的namenode，并配置datanode和客户端使用新的namenode。 为了解决这个问题，Hadoop2增加了对HDFS高可用性（HA）的支持。在这一实现中，配置了一对（活动和备份）namenode。当活动的namenode失效，备用的namenode会接管它的任务，不会有任何明显的中断。实现这一目标需要如下修改： namenode之间通过高可用共享文件系统实现编辑日志的共享。主namenode向文件系统写入数据，而备份namenode读取共享数据实现与主namenode的状态同步。 datanode需要同时向两个namenode发送数据块处理报告。 辅助namenode的角色被备用namenode所包含。 高可用共享文件存储系统常用的有两种：NFS过滤器和群体日志管理器（QJM）。 如果活动和备用的namenode都失效了，管理员依旧可以声明一个备用namenode并实现冷启动。 2.4 故障切换与规避 namenode的切换是由一个称为故障转移控制器（failover controller）的实体操作的，有很多种故障转移控制器，但默认使用ZooKeeper来确保有且仅有一个活动的namenode。其原理就是监控活动的namenode是否失效（心跳机制）并在失效时进行故障切换。注意：我们无法确切的知道判断为失效的namenode是否真的已经停止运行（存在误判的可能）。高可用针对这一问题，作了进一步的优化，以确保之前活动的namenode不会对系统产生影响，该方法称为规避（fencing） ","link":"https://python-spider-wsc.github.io/post/hadoop-qwzn3-hdfs/"},{"title":"AST反混淆","content":"混淆JS 编码转换 混淆的js如下： parseInt(aw('\\x69\\x40\\x5a\\x45', 0x142, 0xd4, -0xa5, 0x1c4)) 可以看到\\x4c\\x70\\x33\\x62 和16进制的数字，首先将这样的混淆解析成功 只需要将extra属性去掉即可，代码如下： path.get('extra').remove(); 四项表达式替换为结果 还可以看到很多这样的四项表达式： -0xb * -0x36d + -0x387 + -0x2228 计算表达式的结果进行替换。 思路： 遍历BinaryExpression 其左右节点是UnaryExpression 或者 NumericLiteral 若左右节点其中是UnaryExpression ，其argument必须是NumericLiteral 将节点的Node转为js语句，使用eval执行得到结果 替换结果 node = path.node //左边不是`number`或者` -number` 或者右边不是， 返回 if(!(t.isNumericLiteral(node.left) || t.isUnaryExpression(node.left)) || !(t.isNumericLiteral(node.right) || t.isUnaryExpression(node.right))) return; if (t.isUnaryExpression(node.left) &amp;&amp; !t.isNumericLiteral(node.left.argument)) return; if (t.isUnaryExpression(node.right) &amp;&amp; !t.isNumericLiteral(node.right.argument)) return; let { code } = generator(node) path.replaceWith(t.NumericLiteral(eval(code))) 自执行函数的实参代替形参 经过上面的转换，可以发现有一部分自执行函数： (function (g, h) { function az(g, h, al, am, an) { return f(am - 799, g); } function aw(g, h, al, am, an) { return f(h - 44, g); } const al = g(); while (true) { try { const am = -parseInt(aw(&quot;i@ZE&quot;, 322, 212, -165, 452)) / 1 * (-parseInt(aw(&quot;i@ZE&quot;, 1588, 2182, 1433, 1510)) / 2) + parseInt(ax(1333, 1138, &quot;13#5&quot;, 1723, 1657)) / 3 * (parseInt(ax(2375, 1308, &quot;#a92&quot;, 1992, 2410)) / 4) + -parseInt(aw(&quot;!($B&quot;, 1669, 2056, 1773, 1584)) / 5 + parseInt(ay(1722, 1422, 647, &quot;z!AQ&quot;, 970)) / 6 + parseInt(ay(1353, 1729, 1554, &quot;#a92&quot;, 1008)) / 7 + parseInt(ay(2124, 1667, 2519, &quot;!($B&quot;, 2071)) / 8 + parseInt(aA(254, 1353, 289, &quot;$HB4&quot;, 899)) / 9 * (-parseInt(az(&quot;Lp3b&quot;, 2104, 1613, 1691, 1388)) / 10); if (am === h) break;else al[&quot;push&quot;](al[&quot;shift&quot;]()); } catch (an) { al[&quot;push&quot;](al[&quot;shift&quot;]()); } } })(e, 642386); 这里要将实参e和642386 直接替换形参g和h，思路如下： 遍历CallExpression CallExpression的callee必须是FunctionExpression， 而且实参个数大于0 遍历每个形参，获取自执行函数的作用域下每个形参的引用 形参必须有引用（无引用则为无效参数，可以删除，如果有对应的实参，也要删除） 如果该形参被修改了（constantViolations不为空数组），直接跳过 遍历该形参的所有引用（referencePaths），替换为对应的实参 移除形参，如果有对应的实参，也要删除 let callee = path.get('callee'); let arguments = path.get('arguments'); if(!t.isFunctionExpression(callee) || arguments.length ===0)return; // callee是FunctionExpression， 而且有实参 let params = callee.get('params'); // 获取形参 let scope = callee.scope; // 一般形参的个数比实参的个数多 for ( let i =0; i&lt; params.length; i++){ let arg = params[i]; let {name} = arg.node; const binding = scope.getBinding(name); if(!binding || (binding.constantViolations.length &gt; 0 &amp;&amp; binding.referencePaths.length&gt;0))continue; for(refer_path of binding.referencePaths){ refer_path.replaceWith(arguments[i]); } arg.remove(); if (i&lt;arguments.length) arguments[i].remove(); } 同时注意，这次遍历应在四项表达式替换完成之后。 子函数的替换 同时观察上面自执行函数的特点，可以发现aw等子函数具有以下特点： 子函数只有一条语句，而且还是返回语句 该返回语句是一个函数调用语句 那么可以直接将aw等子函数使用返回语句替换，同时注意形参和实参的替换。思路如下： 遍历FunctionDeclaration 函数只有一条返回语句，而且该语句是函数调用语句 该函数存在父函数 在父函数空间内，查找该函数的引用 遍历每个函数的引用，用实参替换形参 首先将函数重新转为代码，再进行AST 再次遍历FunctionDeclaration 执行将形参替换为实参 将函数的引用替换为解析完实参的调用函数 代码如下： let body = path.get(&quot;body&quot;); // 函数体 // 函数只有一条返回语句，而且该语句是函数调用语句 if (!(t.isBlockStatement(body) &amp;&amp; body.node.body.length==1 &amp;&amp;t.isReturnStatement(body.node.body[0])&amp;&amp;t.isCallExpression(body.node.body[0].argument))) return; parent = path.getFunctionParent(); // 父函数 if(!parent) return; // 函数的作用域 let binding = parent.scope.getBinding(path.node.id.name); // 函数名 let paths = binding.referencePaths; // 找到函数的每个引用 let { code } = generator(path.node) // 函数有多个引用不能直接修改函数 for (let i = 0; i &lt; paths.length; i++) { let args = paths[i].parent.arguments; // 实参 var newAst = parser.parse(code); // 重新生成函数，可以直接修改函数 // 直接替换函数的形参和实参 traverse(newAst,{ FunctionDeclaration(_path) { let params = _path.get('params') //形参 let subFuncScope = _path.scope; // 函数内部的作用域 for (let j = 0; j &lt;args.length; j++) { let {name} = params[j].node; //形参名 const binding = subFuncScope.getBinding(name); for(refer_path of binding.referencePaths){ refer_path.replaceWith(args[j]); } } paths[i].parentPath.replaceWith(_path.get(&quot;body&quot;).node.body[0].argument) } }); } 应该存在不需要将函数重新转为代码的方法，暂时记下，以后研究。 清除未调用的函数 经过上面的函数的替换操作后，会有很多未调用的函数，需要删除，删除操作很简单： 遍历FunctionDeclaration 在父作用域下，查找该函数的引用 引用为0，即可删除该函数。 问题是经过上面的操作，AST没有更新，即仍存在该函数的引用，不知道该怎么办。只能保存在文件，再次读取文件，进行删除函数的操作。 函数调用还原为结果字符串 经过上面操作之后，发现又出现了四项表达式，再次调用上面的代码还原。 继续观察，发现有很多f(a1, a2)的函数调用，分析以下，该函数应该是个解密函数，接下来就要把该函数的调用替换为结果字符串。 可以看出f(a1, a2)确实是解密函数，我们要把这个函数剪切到另一个解密文件中，并让其可以运行，这样就可以直接调用这个函数得到解密结果，替换所有的f(a1, a2)的函数调用。 可以发现还少了一个e()函数，同样剪切出来： 可以发现这个e()函数其实就是个大数组，很像OB混淆。 然后随便找一个解密函数f(278, &quot;i@ZE&quot;), 在这个新的解密文件中执行解密，发现竟然报内存溢出的错误，难道是之前的反混淆操作出错了？还好这个解密文件还算简单，仔细看一下哪里出问题了： 果然这里定义了个函数this[&quot;NADmAW&quot;]，同时使用正则表达式检测该函数是否格式化，如果格式化，则进入死循环。 将这个函数压缩一下，继续执行，发现果然不报错了，但是执行的结果却是乱码，显然不对。这里回到反混淆之后的代码看一下： 一般OB混淆都会对大数组进行移位操作，这里果然也有，同样剪切出来，这样就可以了。之后就是反混淆了，思路如下： 从解密文件中引入解密函数 遍历CallExpression， 判断函数名是解密函数 将参数传入解密函数，得到结果代替CallExpression let node = path.node; // 函数名字相同 if (!t.isIdentifier(node.callee, {name: decryptStrFnName})) return; try { const result = decryptStr(node.arguments[0].value, node.arguments[1].value) path.replaceWith(t.stringLiteral(result)) } catch (error) { console.log(node.arguments[0].value, node.arguments[1].value) } 解密之后，又出现大量的字符串相加的情况，再次调用上面的代码还原。 成员表达式转成属性表达式 把a[&quot;b&quot;]转成a.b，更容易阅读（慎用，有可能会出错，比如属性包含特殊符号（-+）） 思路如下： 遍历MemberExpression property必须是StringLiteral 把computed置成false，然后把value变成Identifier 代码如下： let property = path.get('property'); if (!t.isStringLiteral(property)) return; let value = property.node.value; if(value.indexOf(&quot;-&quot;)&gt;0) return; path.node.computed = false; property.replaceWith(t.Identifier(value)) 修改逗号表达式 逗号表达式也不利于阅读，把逗号表达书拆分出来，因为逗号表达式应用过于灵活，暂时还原部分逗号表达式。 思路如下： 遍历SequenceExpression 判断是否存在父级语句块getStatementParent 在父级语句前插入其他的逗号语句 let expressions = path.get('expressions'); let last_expression = expressions.pop(); let parentStatement = path.getStatementParent(); if(parentStatement){ for(let expression of expressions){ // 删除无用的干扰代码 if(expression.isLiteral() ||expression.isIdentifier()){ expression.remove(); continue; } parentStatement.insertBefore(t.ExpressionStatement(expression=expression.node)); } path.replaceInline(last_expression); } 最后看一下反混淆的成果： ","link":"https://python-spider-wsc.github.io/post/ast-fan-hun-yao/"},{"title":"逻辑回归的算法思想与实现","content":"逻辑回归虽然是回归，但是经常用来处理分类问题。那是因为它回归的是属于某一类别的概率。 sigmoid非线性函数 sigmoid函数如下： g(z)=11+e−zg(z)=\\frac{1}{1+e^{-z}} g(z)=1+e−z1​ 其趋势： 通过图片可以看到以下几点： 对于任意实数，其值都在[0, 1]之间，且在x=0处值为0。 整个函数单调递增且非线性变化。 因此可以根据g(z)的值是否大于0.5来判断样本x属于正类还是反类。 回归模型与sigmoid函数 首先，假设构造的回归模型如下： f(x)=∑n=1Nwi∗xi=W∗Xf(x) = \\sum_{n=1}^{N}{w_i*x_i}= W*X f(x)=n=1∑N​wi​∗xi​=W∗X 其中N表示样本的维度数。 然后，将回归之后的值f(x)f(x)f(x)代入sigmoid函数，得到一个概率值为h(x)h(x)h(x)，如下： h(x)=g(f(x))=11+e−f(x)h(x)=g(f(x))=\\frac{1}{1+e^{-f(x)}} h(x)=g(f(x))=1+e−f(x)1​ 即： h(x)=ef(x)1+ef(x)h(x)=\\frac{e^{f(x)}}{1+e^{f(x)}} h(x)=1+ef(x)ef(x)​ ef(x)=h(x)1−h(x)e^{f(x)} = \\frac{h(x)}{1-h(x)} ef(x)=1−h(x)h(x)​ f(x)=logh(x)1−h(x)f(x)=log\\frac{h(x)}{1-h(x)} f(x)=log1−h(x)h(x)​ 如果h(x)h(x)h(x)表示正类的概率，则1−h(x)1-h(x)1−h(x)表示负类的概率。 f(x)=W∗X=logh(x)1−h(x)f(x) = W*X = log\\frac{h(x)}{1-h(x)} f(x)=W∗X=log1−h(x)h(x)​ 这里的h(x)h(x)h(x)就满足sigmoid函数的特性，这样就建立了f(x)f(x)f(x)与h(x)h(x)h(x)联系 损失函数 现在已经知道了任意样本属于正类的概率分布h(x)h(x)h(x)，那就可以使用最大似然估计表示损失函数。 最大似然估计：在已知概率分布模型，而未知模型参数的情况下，如果某个参数能使样本出现的概率最大，就把这个参数作为估计的真实值。 现在的思路就是所有正类样本的h(x)h(x)h(x)最大，同时所有负类样本的h(x)h(x)h(x)最小（即1−h(x)1-h(x)1−h(x)最大）。同时优化 h(x)h(x)h(x)和1−h(x)1-h(x)1−h(x)，使其最大，比较麻烦，可以使用如下的损失函数： p(yi∣xi)=p(yi=1∣xi)yi∗(p(yi=0∣xi)(1−yi))p(y_i|x_i) = p(y_i=1|x_i)^{y_i}*(p(y_i=0|x_i)^{(1-y_i)}) p(yi​∣xi​)=p(yi​=1∣xi​)yi​∗(p(yi​=0∣xi​)(1−yi​)) 即： p(yi∣xi)=h(xi)yi∗(1−h(xi))(1−yi)p(y_i|x_i) = h(x_i)^{y_i}*(1-h(x_i))^{(1-y_i)} p(yi​∣xi​)=h(xi​)yi​∗(1−h(xi​))(1−yi​) 这样做，无论样本是正类还是负类，只要使得p(yi∣xi)p(y_i|x_i)p(yi​∣xi​)最大即可。 样本之间互相独立，那么n个样本出现的似然度为： L(w)=∏i=1nP(yi∣xi)=∏i=1nh(xi)yi∗(1−h(xi))(1−yi)L(w)=\\prod_{i=1}^{n}{P(y_i|x_i)} = \\prod_{i=1}^{n}{h(x_i)^{y_i}*(1-h(x_i))^{(1-y_i)}} L(w)=i=1∏n​P(yi​∣xi​)=i=1∏n​h(xi​)yi​∗(1−h(xi​))(1−yi​) 只要求取L(w)L(w)L(w)的最大值即可，此时对应的www就是最优的模型参数。 一般来说，我们更喜欢求取最小值，而且上面公式中包含累乘，这对使用梯度法求解很不友好。对损失函数做如下变化： L(w)=−1nlog∏i=1nP(yi∣xi)=−1nlog∏i=1nh(xi)yi∗(1−h(xi))(1−yi)=−1n(∑i=1nlogh(xi)yi+∑i=1nlog(1−h(xi))(1−yi))=−1n(∑i=1nyi∗logh(xi)+∑i=1n(1−yi)∗log(1−h(xi)))=−1n(∑i=1nyi∗logh(xi)+∑i=1nlog(1−h(xi))−∑i=1nyi∗log(1−h(xi)))=−1n(∑i=1nyi∗logh(xi)1−h(xi)+∑i=1nlog(1−h(xi)))=−1n(∑i=1nyi∗f(xi)+∑i=1nlog(1−11+e−f(xi)))=−1n(∑i=1nyi∗f(xi)+∑i=1nlog1ef(xi)+1)=−1n(∑i=1nyi∗f(xi)−∑i=1nlog(ef(xi)+1))\\begin{aligned} L(w) &amp;=-\\frac{1}{n}log\\prod_{i=1}^{n}{P(y_i|x_i)} = -\\frac{1}{n}log\\prod_{i=1}^{n}{h(x_i)^{y_i}*(1-h(x_i))^{(1-y_i)}} \\\\ &amp;=-\\frac{1}{n}(\\sum_{i=1}^{n}{logh(x_i)^{y_i}} +\\sum_{i=1}^{n}{log(1-h(x_i))^{(1-y_i)}}) \\\\ &amp;= -\\frac{1}{n}(\\sum_{i=1}^{n}{y_i*logh(x_i)}+\\sum_{i=1}^{n}{(1-y_i)*log(1-h(x_i))}) \\\\ &amp;=-\\frac{1}{n}(\\sum_{i=1}^{n}{y_i*logh(x_i)}+\\sum_{i=1}^{n}{log(1-h(x_i))}-\\sum_{i=1}^{n}{y_i*log(1-h(x_i))}) \\\\ &amp; = -\\frac{1}{n}( \\sum_{i=1}^{n}{y_i*log\\frac{h(x_i)}{1-h(x_i)}}+\\sum_{i=1}^{n}{log(1-h(x_i))}) \\\\ &amp; = -\\frac{1}{n}(\\sum_{i=1}^{n}{y_i*f(x_i)}+\\sum_{i=1}^{n}{log(1-\\frac{1}{1+e^{-f(x_i)}})}) \\\\ &amp; = -\\frac{1}{n}( \\sum_{i=1}^{n}{y_i*f(x_i)}+ \\sum_{i=1}^{n}{ log\\frac{1}{e^{f(x_i)}+1}}) \\\\ &amp; = -\\frac{1}{n}( \\sum_{i=1}^{n}{y_i*f(x_i)} - \\sum_{i=1}^{n}{ log(e^{f(x_i)}+1)}) \\end{aligned}L(w)​=−n1​logi=1∏n​P(yi​∣xi​)=−n1​logi=1∏n​h(xi​)yi​∗(1−h(xi​))(1−yi​)=−n1​(i=1∑n​logh(xi​)yi​+i=1∑n​log(1−h(xi​))(1−yi​))=−n1​(i=1∑n​yi​∗logh(xi​)+i=1∑n​(1−yi​)∗log(1−h(xi​)))=−n1​(i=1∑n​yi​∗logh(xi​)+i=1∑n​log(1−h(xi​))−i=1∑n​yi​∗log(1−h(xi​)))=−n1​(i=1∑n​yi​∗log1−h(xi​)h(xi​)​+i=1∑n​log(1−h(xi​)))=−n1​(i=1∑n​yi​∗f(xi​)+i=1∑n​log(1−1+e−f(xi​)1​))=−n1​(i=1∑n​yi​∗f(xi​)+i=1∑n​logef(xi​)+11​)=−n1​(i=1∑n​yi​∗f(xi​)−i=1∑n​log(ef(xi​)+1))​ 至此，已经找到了损失函数和回归函数f(x)的关系，最优化损失函数，求出相对的f(x)，也就找到了回归因子W。 损失函数的梯度 首先： ∂f(x)∂W=X\\frac{\\partial f(x)}{\\partial W} = X ∂W∂f(x)​=X 然后 ∂L(W)∂W=−1n∂∂W(∑i=1nyi∗f(xi)−∑i=1nlog(ef(xi)+1))=−1n(∑i=1nyi∗xi−∑i=1n1ef(xi)+1ef(xi)∂f(x)∂W)=−1n(∑i=1nyi∗xi−∑i=1n1ef(xi)+1ef(xi)xi)=−1n∑i=1nxi∗(yi−ef(xi)ef(xi)+1)=−1n∑i=1nxi∗(yi−h(xi))\\begin{aligned} \\frac{\\partial L(W)}{\\partial W} &amp;= -\\frac{1}{n}\\frac{\\partial}{\\partial W}( \\sum_{i=1}^{n}{y_i*f(x_i)} - \\sum_{i=1}^{n}{ log(e^{f(x_i)}+1)}) \\\\ &amp; = -\\frac{1}{n}(\\sum_{i=1}^{n}{y_i*x_i} - \\sum_{i=1}^{n}{ \\frac{1}{e^{f(x_i)}+1}}e^{f(x_i)}\\frac{\\partial f(x)}{\\partial W}) \\\\ &amp; = -\\frac{1}{n}(\\sum_{i=1}^{n}{y_i*x_i} - \\sum_{i=1}^{n}{ \\frac{1}{e^{f(x_i)}+1}}e^{f(x_i)}x_i) \\\\ &amp; = -\\frac{1}{n}\\sum_{i=1}^{n}{x_i*(y_i-\\frac{e^{f(x_i)}}{e^{f(x_i)}+1}}) \\\\ &amp; = -\\frac{1}{n}\\sum_{i=1}^{n}{x_i*(y_i-h(x_i))} \\end{aligned}∂W∂L(W)​​=−n1​∂W∂​(i=1∑n​yi​∗f(xi​)−i=1∑n​log(ef(xi​)+1))=−n1​(i=1∑n​yi​∗xi​−i=1∑n​ef(xi​)+11​ef(xi​)∂W∂f(x)​)=−n1​(i=1∑n​yi​∗xi​−i=1∑n​ef(xi​)+11​ef(xi​)xi​)=−n1​i=1∑n​xi​∗(yi​−ef(xi​)+1ef(xi​)​)=−n1​i=1∑n​xi​∗(yi​−h(xi​))​ 只要令其导数为0，就可以得到极值点，从而确定回归因子W。遗憾的是这个导数无法直接求解，所以我们需要使用梯度法求解极值点。 ","link":"https://python-spider-wsc.github.io/post/luo-ji-hui-gui-de-suan-fa-si-xiang-yu-shi-xian/"}]}